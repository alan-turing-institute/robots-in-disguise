## Previous sessions

This page shows a history of previous sessions in the reading group. 

|Date | Topic | Room | Lead |
| --- | ----- | ---- | ---- |
| [20/03/23](#200323) | Introduction to word embeddings and language modelling ([Slides](https://docs.google.com/presentation/d/1i56HKtjcdQFTxacxsjgya_giDx8Mv1xZn-IDNc_mK8I/edit?usp=sharing)) | David Blackwell | [Fede Nanni](https://github.com/fedenanni) |
| [03/04/23](#030423) | Deep Learning Basics ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/02-deep-learning/Robots_Neural_Networks_2023-04-03.pptx)) | David Blackwell | [Phil Swatton](https://github.com/philswatton), [Jack Roberts](https://github.com/jack89roberts) |
| [17/04/23](#170423) | Sequence-to-sequence models part I: RNNs/LSTMs ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/03-seq2seq-part-i/seq2seq_part1_hut23_robots_in_disguise.pdf)) | David Blackwell | [Ryan Chan](https://github.com/rchan26) |
| [03/05/23](#030523) | Sequence-to-sequence models part II: Encoder-decoder models ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/04-seq2seq-part-ii/seq2seq_part2_hut23_robots_in_disguise.pdf)) | David Blackwell | [Ryan Chan](https://github.com/rchan26) |
| 15/05/23 | Hands-on RNN/LSTM session ([Materials](https://github.com/phinate/jax-rnn))| David Blackwell | [Nathan Simpson](https://github.com/phinate), [Levan Bokeria](https://github.com/lbokeria), [David Llewellyn-Jones](https://github.com/llewelld) |
| [31/05/23](#310523) | Reginald overview & Attention and self-attention networks ([Notebook](https://github.com/alan-turing-institute/foundation-models-reading-group/tree/main/REGinalds/gpt2-demo)) | David Blackwell | [Evelina Gabasova](https://github.com/evelinag), [Martin Stoffel](https://github.com/mastoffel) |
| [26/06/23](#260623) | Attention (continued) ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/05-attention/attention.pdf)) & Transformer Encoder and Decoders ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/06-transformers-architecture/transformer_architecture_hut23_robots_in_disguise.pdf)) | David Blackwell | [Martin Stoffel](https://github.com/mastoffel), [Ryan Chan](https://github.com/rchan26) |
| [10/07/23](#100723) | BERT: Masked Language modelling and Pre-training ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/07-bert/bert_hut23_robots_in_disguise.pdf)) | David Blackwell | [Ryan Chan](https://github.com/rchan26) |
| [24/07/23](#240723) | GPT: Pretraining Decoders ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/08-gpt/gpt_hut23_robots_in_disguise.pdf)) | David Blackwell | [Ryan Chan](https://github.com/rchan26) |
| [07/08/23](#070823) | Vision Transformers part I ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/09-vision-transformers-part-i/vision_transformer_part1_hut23_robots_in_disguise.pdf)) | David Blackwell | [Katie Awty-Carroll](https://github.com/klh5), [Ryan Chan](https://github.com/rchan26) |
| [21/08/23](#210823) | Vision Transformers part II ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/10-vision-transformers-part-ii/vision_transformer_part2_hut23_robots_in_disguise.pdf)) | David Blackwell | [Katie Awty-Carroll](https://github.com/klh5) |
| [18/09/23](#180923) | LoRA (+ parameter efficient fine-tuning) part I ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/11-peft/20230915_PEFT.pdf)) | David Blackwell | [Jack Roberts](https://github.com/jack89roberts) |
| [25/09/23](#180923) | LoRA (+ parameter efficient fine-tuning) part II ([Notebook](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/11-peft/peft.ipynb)) | Margaret Hamilton | [Jack Roberts](https://github.com/jack89roberts) |
| [02/10/23](#021023) | Reinforcement Learning Human Feedback (RLHF) ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/12-rlhf/2023-10-02-rlhf.pdf)) | David Blackwell | [Eseoghene Ben-Iwhiwhu](https://github.com/dlpbc) |
| [16/10/23](#161023) | Prompt Engineering ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/13-prompt-engineering/prompts.pdf)) | David Blackwell | [Martin Stoffel](https://github.com/mastoffel) |
| [30/10/23](#301023) | Technical: Knowledge retrieval ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/14-knowledge-retrieval-fms/Knowledge_Retrieval_FMs.pdf)) | David Blackwell | [Praveen Selvaraj](https://github.com/pravsels) |
| [06/11/23](#061123) | Discussion: Current challenges and future directions in safety evaluations for generative AI ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/15-safety-evaluations-for-generative-ai/safety-evals-for-gen-ai.pdf)) | David Blackwell | [Jonathan Bright](https://www.turing.ac.uk/people/researchers/jonathan-bright) |
| [13/11/23](#131123) | Technical: Introduction to Diffusion models ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/16-diffusion-models/intro_to_diffusion_models.pdf)) | David Blackwell | [Edmund Dable-Heath](https://github.com/eddableheath) |
| [20/11/23](#201123) | Research at Turing: Transformers for coding/software engineering ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/17-trasformers-for-coding/transformers-for-software-engineering-and-earlybird.pdf)) | Mae Jemison | [Anastasiia Grishina](https://www.turing.ac.uk/people/enrichment-students/anastasiia-grishina) |
| [04/12/23](#041223) | Discussion: Best Practice for Responsible Foundation Models – What Should Developers Do and How You Can Help ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/18-best-practice-for-responsible-foundation-models/Best-Practice-for-Responsible-Foundation-Models.pdf)) | Ursula Franklin | [Carolyn Ashurst](https://www.turing.ac.uk/people/turing-research-fellows/carolyn-ashurst) |
| [11/12/23](#111223) | Technical: Stable Diffusion  ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/tree/main/sessions/19-stable-diffusion/stable_diffusion.pdf)) | David Blackwell | [Edmund Dable-Heath](https://github.com/eddableheath) |
| [08/01/24](#080124) | Discussion: Benchmarking AI applications on GPUs ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/20-benchmarking-gpus/transformers-rcp-benchmarking.pdf)) | David Blackwell | [Tomas Lazauskas](https://github.com/tomaslaz), [David Llewellyn-Jones](https://github.com/llewelld) |
| [15/01/24](#150124) | Technical: Retentive Networks ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/tree/main/sessions/21-retentive-networks/RetentiveNetworks.pdf)) | David Blackwell | [Ed Gunn](https://github.com/egunn-turing) |
| [22/01/24](#220124) | Research at Turing: Spatial Graph Patterning of Filamentous Structures | David Blackwell | [Kristina Ulicna](https://www.turing.ac.uk/people/research-associates/kristina-ulicna)|
| [29/01/24](#290124) | Technical: Vision Transformers Need Registers ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/23-vision-transformers-need-registers/vision-transformers-need-registers.pdf)) | David Blackwell | [Tom Davies](tomogwen) |
| [05/02/24](#050224) | Discussion: Existential Risk of AI? ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/24-ai-existential-risk/2024-02-05-Bokeria-AI-x-risk.pdf)) | David Blackwell | [Levan Bokeria](https://www.turing.ac.uk/people/research-engineering/levan-bokeria) |
| [12/02/24](#120224) | Technical: Mechanistic interpretability ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/25-mechanistic-interpretability/Mech%20Interp%20Intro%2C%20FM%20Reading%20Group.pdf)) | David Blackwell | [Praveen Selvaraj](https://github.com/pravsels) |
| [19/02/24](#190224) | Research at Turing: Longitudinal NLP ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/26-longitudinal-nlp/Dynamic%20Language%20Modelling_190224_reduced.pdf)) | David Blackwell | [Jenny Chim](https://j-chim.github.io/), [Talia Tseriotou](https://github.com/ttseriotou) |
| [26/02/24](#260224) | Research at Turing: Machine translation quality estimation ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/27-machine-translation-quality-estimation/MTQE_2024-02-26_Foundation_Models_Reading_Group.pdf)) | David Blackwell | [Radka Jersakova](https://www.turing.ac.uk/people/researchers/radka-jersakova), [Jo Knight](https://www.turing.ac.uk/people/researchers/joanna-knight) |
| [04/03/24](#040324) | Discussion: Expanding participatory governance for LLMs: case studies from BigCode, Aya Initiative, and Collective Intelligence Project ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/28-participatory-ai-governance/2024_ParticipatoryAIGovernance_JD.pdf)) | David Blackwell | [Jennifer Ding](https://www.turing.ac.uk/people/business-team/jennifer-ding) |
| [11/03/24](#110324) | Research at Turing: Applying Vision Transformers in Neuroscience ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/29-applying-vision-transformers-in-neuroscience/2024-03-11-foundation-model-of-the-mouse-visual-cortex.pdf)) | David Blackwell | [Bryan Li](https://bryanli.io/) |
| [18/03/24](#180324) | Research at Turing: Not even a Chinese Room: evaluating LLMs on code simulation | David Blackwell | [Emanuele La Malfa](https://www.cs.ox.ac.uk/people/emanuele.lamalfa/) |
| [08/04/24](#080424) | Technical: Paper overviews ([Slides](https://image-editing.notion.site/Representation-Engineering-a451cb7f5af048b6878bc96396dac5a1), [Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/31-quick-paper-overviews/Quick_overview_Binoculars_Paper.pdf)) | Ursula Franklin | [Fede Nanni](https://github.com/fedenanni), [Markus Hauru](https://github.com/mhauru/), [Praveen Selvaraj](https://github.com/pravsels) |
| [15/04/24](#150424) | Research at Turing: Natural Logic-based Fact Verification with LLMs | David Blackwell | [Marek Strong](https://marekstrong.github.io/)  |
| [22/04/24](#220424) | Research at Turing: Learn how to learn and distil during learning - Using meta-learning and second order optimisation to prune the model | David Blackwell | [Yilei Liang](https://www.cst.cam.ac.uk/people/yl841) |
| [29/04/24](#290424) | Invited Talk: How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/34-how-to-catch-ai-liar/LLM_Lie_detection.pdf)) | David Blackwell | [Lorenzo Pacchiardi](http://www.lorenzopacchiardi.me/) |
| [13/05/24](#130524) | Technical: Overview of LLM Security ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/35-llm-security/LLM_Security_slides.pdf)) | David Blackwell | [Ed Chapman](https://www.turing.ac.uk/people/research-engineering/edward-chapman), [Burak Hasircioglu](https://www.turing.ac.uk/people/researchers/burak-hasircioglu), [Ezzeldin Zaki](https://www.kth.se/profile/eshereen) |
| [20/05/24](#200524) | Technical: KAN: Kolmogorov-Arnold Networks | Ursula Franklin | [Andrew Duncan](https://www.turing.ac.uk/people/researchers/andrew-duncan) |
| [04/06/24](#040624) | Invited Talk: Are we ready for attacks on machine learning? | Enigma (2.30pm) | [Nicholas Carlini](https://nicholas.carlini.com/) |
| [01/07/24](#010724) | Technical: A perspective on the fundamentals of transformers ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/38-a-perspective-on-the-fundamentals-of-transformers/a_perspective_on_the_fundamentals_of_transformers_slide.pdf)) | Ursula Franklin | Ed Gunn |
| [08/07/24](#080724) | Invited Talk: Equally Safe Online? A participatory approach to tackling Gender-Based Violence ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/39-perspectivism-in-nlp/gavin-abercrombie-talk.pdf)) | David Blackwell | [Gavin Abercrombie](https://gavinabercrombie.github.io/) |
| [15/07/24](#150724) | Invited Talk: Open science projects for open-source models and transparent open datasets | Cipher | [Christopher Klamm](https://chkla.github.io/gitPage/) |
| [22/07/24](#220724) | Invited Talk: Designing a Value-driven GAI Framework for Social Good: Embedding Social Good Values into GAI Models ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/41-value-driven-gai-framework-for-social-good/AI_system_with_social_good.pdf)) | Ursula Franklin | [Victor OK Li](https://www.eee.hku.hk/people/vli/), [Jacqueline CK Lam](https://www.eee.hku.hk/people/jcklam/) and [Jon Crowcroft](https://www.turing.ac.uk/people/researchers/jon-crowcroft) |
| [05/08/24](#050824) | Invited Talk: The growth of parallelism in machine learning inference ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/42-parallelism-in-ml-inference/2024-08-Tim-Harris.pdf)) | Ursula Franklin | [Tim Harris (Microsoft)](https://timharris.uk/) |
| [12/08/24](#120824) | Llama 3.1 Report Overview ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/43-llama31/llama-3-1.pdf)) | Ursula Franklin | [Edwin Brown](https://github.com/EdwinB12), [Ryan Chan](https://github.com/rchan26) |
| [19/08/24](#190824) | Overview of Knowledge Graphs ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/44-knowledge-graphs/Turing-KG-Talk.pdf)) | David Blackwell |[Navdeep Kaur](https://www.turing.ac.uk/people/navdeep-kaur) |
| [28/08/24](#280824) | Technical: Mixture of Experts ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/45-mixture-of-experts/moe-slides.pdf)) | Jack Good | [Angus R Williams](https://angusrw.com/) |
| [03/09/24](#030924) | Invited Talk: Sociotechnical Safety Evaluation of AI systems ([Slides](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/46-sociotechnical-safety-eval-of-AI/Safety-Evaluation-of-generative-AI.pdf)) | Enigma | [Laura Weidinger](https://scholar.google.com/citations?user=SFQLTCkAAAAJ&hl=en) |

# Material for sessions

## 20/03/23
### Introduction to Word Embeddings and Language modelling

**Main**
- [Don't Count, Predict! paper](https://aclanthology.org/P14-1023.pdf)
- [Word Embeddings (1)](https://www.ruder.io/word-embeddings-1/)
- [Word Embeddings (2)](https://www.ruder.io/word-embeddings-softmax/)
- [Word Embeddings (3)](https://www.ruder.io/secret-word2vec/)
- [Brief History of NLP (part 1)](https://medium.com/@antoine.louis/a-brief-history-of-natural-language-processing-part-1-ffbcb937ebce)
- [Brief History of NLP (part 2)](https://medium.com/@antoine.louis/a-brief-history-of-natural-language-processing-part-2-f5e575e8e37)

**Extra**
- [Deep Learning, NLP and Representations](http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/)
- [Stanford NLP with Deep Learning | Lecture 1: Intro & Word Vectors](https://youtu.be/rmVRLeJRkl4)
- [Speech and Language Processing - Chapter 6: Vector Semantics and Embeddings](https://web.stanford.edu/~jurafsky/slp3/6.pdf)
- [Stanford Large Language Models | Lecture 1: Introduction](https://stanford-cs324.github.io/winter2022/lectures/introduction/)
    
## 03/04/23
### Deep Learning Basics

**Main**
- [Neural Networks and Deep Learning | Chapter 1: Using neural nets to recognize handwritten digits](http://neuralnetworksanddeeplearning.com/chap1.html)
- [Neural Networks and Deep Learning | Chapter 2: How the backpropagation algorithm works](http://neuralnetworksanddeeplearning.com/chap2.html)
  - Alternatively, come along to [Phil and Jack's Lunchtime Tech Talk](https://github.com/alan-turing-institute/DataScienceSkills/wiki/Lunchtime-Tech-Talks) on Back Propagation (April 11th) - message on the `#hut23-robots-in-disguise` slack if you want to get a calendar invite for the session

**Extra**
- [Learning Deep Learning | Chapters 1 and 2](https://jack89roberts.github.io/learning-deep-learning/index.html)
- [Neural Networks by Hand | Feedforward Neural Networks](https://philswatton.github.io/neural-networks-by-hand/feedforward-neural-network.html)
- [Andrej Karparthy (YouTube): The spelled-out intro to neural networks and backpropagation](https://youtu.be/VMj-3S1tku0)

## 17/04/23
### Sequence-to-sequence models part I: RNNs/LSTMs

**Main**
- [Speech and Language Processing | Chapter 9: RNNs and LSTMs](https://web.stanford.edu/~jurafsky/slp3/9.pdf)
  - Read up to Section 9.5 (read pages 1-13)

**Extra**
- [The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)
- [NLP with Deep Learning Stanford Course | Lecture 5](https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes05-LM_RNN.pdf)
  - Read up to Section 3 (read pages 1-11)
- [Stanford NLP with Deep Learning | Lecture 5: RNNs)](https://you.be/PLryWeHPcBs)

## 03/05/23
### Sequence-to-sequence models part II: Encoder-decoder models

**Main**
- [Speech and Language Processing | Chapter 9: RNNs and LSTMs](https://web.stanford.edu/~jurafsky/slp3/9.pdf)
  - Read from 9.5 to 9.8 (read pages 14-21)
  
**Extra**
- [Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)
- [NLP with Deep Learning Stanford Course | Lecture 5](https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes05-LM_RNN.pdf)
  - Read from Section 3 (read pages 11 onwards)
- [Stanford NLP with Deep Learning | Lecture 6: Simple LSTM RNNs](https://youtu.be/0LixFSa7yts)

## 31/05/23
### Attention

**Main**
- [Attention is all you need](https://arxiv.org/abs/1706.03762)

**Extra**
- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
- [Andrej Karpathy's GPT-2 from scratch](https://www.youtube.com/watch?v=kCc8FmEb1nY&t=4766s)
- [Anthropic's Transformer Circuits](https://transformer-circuits.pub/2021/framework/index.html)
- [NLP with Deep Learning Stanford Course | Lecture 6](https://web.stanford.edu/class/cs224n/readings/cs224n-2019-notes06-NMT_seq2seq_attention.pdf)
- [Attention and Augmented Recurrent Neural Networks](https://distill.pub/2016/augmented-rnns/)
- [Stanford NLP with Deep Learning | Lecture 7: Translation, Seq2Seq, Attention](https://youtu.be/wzfWHP6SXxY)
- [Stanford NLP with Deep Learning | Lecture 9: Self- Attention and Transformers](https://youtu.be/ptuGllU5SQQ)
- [Michigan Deep Learning for Comp Vis | Lecture 13: Attention](https://www.youtube.com/watch?v=YAgjfMR9R_M)

## 26/06/23
### Transformer Encoder and Decoders

**Main**
- [Attention is all you need](https://arxiv.org/abs/1706.03762)
- [The Illustrated Transformer](https://jalammar.github.io/illustrated-transformer/)
- [The Annotated Transformer](http://nlp.seas.harvard.edu/annotated-transformer/)

**Extra**
- [Speech and Language Processing | Chapter 9: RNNs and LSTMs](https://web.stanford.edu/~jurafsky/slp3/9.pdf)
  - Read from 9.8 (read pages from 21 onwards)
- [Speech and Language Processing | Chapter 10: Transformers and Pretrained Language Models](https://web.stanford.edu/~jurafsky/slp3/10.pdf)
- [NLP with Deep Learning Stanford Course | Self-Attention & Transformers](https://web.stanford.edu/class/cs224n/readings/cs224n-self-attention-transformers-2023_draft.pdf)

## 10/07/23
### BERT: Masked Language modelling and Pre-training

**Main**
- [BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding](https://arxiv.org/pdf/1810.04805.pdf)

**Extra**
- [Speech and Language Processing | Chapter 11: Fine-Tuning and Masked Language Models](https://web.stanford.edu/~jurafsky/slp3/11.pdf)
- [The Illustrated BERT](http://jalammar.github.io/illustrated-bert/)
- [BERT 101 🤗 State Of The Art NLP Model Explained](https://huggingface.co/blog/bert-101)
- [Paper summary — BERT](https://medium.com/analytics-vidhya/paper-summary-bert-pre-training-of-deep-bidirectional-transformers-for-language-understanding-861456fed1f9)

## 24/07/23
### GPT: Pretraining Decoders

**Main**
- [Improving Language Understanding by Generative Pre-Training](https://cdn.openai.com/research-covers/language-unsupervised/language_understanding_paper.pdf)

**Extra**
- [Paper summary - Improving Language Understanding by Generative Pre-Training](https://sh-tsang.medium.com/review-gpt-improving-language-understanding-by-generative-pre-training-28f30d39cd10)
- [Language Models are Unsupervised Multitask Learners](https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf)

**Note** the below materials for other sessions, or are not confirmed

## 07/08/23
### Vision Transformers part I

**Main**
- [Gradient Based Learning Applied to Document Recognition](https://ieeexplore.ieee.org/document/726791)
- [An Image Is Worth 16x16 Words: Transformers for Image Recongition at scale](https://arxiv.org/pdf/2010.11929.pdf)

**Extra**
- [Vision Transformer for Image Classification - Shusen Wang (YouTube)](https://youtu.be/HZ4j_U3FC94)
- [Neocognitron: A Self-organizing Neural Network Model
for a Mechanism of Pattern Recognition
Unaffected by Shift in Position](https://www.rctn.org/bruno/public/papers/Fukushima1980.pdf)
- [But what is a convolution? - 3Blue1Brown (YouTube)](https://www.youtube.com/watch?v=KuXjwB4LzSA&t=705s)
- [CNN Explainer](https://poloclub.github.io/cnn-explainer/)

## 21/08/23
### Vision Transformers part II

**Main**
- [Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers](https://arxiv.org/abs/2012.15840)

**Extra**
- [End-to-End Object Detection with Transformers](https://arxiv.org/abs/2005.12872)

## 18/09/23
### LoRA (+ parameter efficient fine-tuning)

**Main**
- [Huggingface PEFT library](https://huggingface.co/docs/peft/index)

**Extra**
- [LoRA: Low-Rank Adaption of Large Language Models](https://arxiv.org/pdf/2106.09685.pdf)
- [LoRA conceptual guide](https://huggingface.co/docs/peft/conceptual_guides/lora)

## 02/10/23
### Reinforcement Learning Human Feedback (RLHF)

**Main**
- [RLHF: Reinforcement Learning from Human Feedback](https://huyenchip.com/2023/05/02/rlhf.html)
- [Illustrating Reinforcement Learning from Human Feedback (RLHF)](https://huggingface.co/blog/rlhf)

**Extra**
- [An introduction to Reinforcement Learning](https://youtu.be/JgvyzIkgxF0)
- [Understanding Reinforcement Learning from Human Feedback (RLHF): Part 1](https://wandb.ai/ayush-thakur/RLHF/reports/Understanding-Reinforcement-Learning-from-Human-Feedback-RLHF-Part-1--VmlldzoyODk5MTIx)
- [Open Problems and Fundamental Limitations of Reinforcement Learning from Human Feedback](https://arxiv.org/abs/2307.15217)
- [Secrets of RLHF in Large Language Models Part I: PPO](https://arxiv.org/abs/2307.04964)

**Beyond RLHF**
- [Reinforced Self-Training (ReST) for Language Modeling](https://arxiv.org/abs/2308.08998)
- [Direct Preference Optimization: Your Language Model is Secretly a Reward Model](https://arxiv.org/abs/2305.18290)

## 16/10/23
### Prompt Engineering

**Guides**
- [Anthropic](https://docs.anthropic.com/claude/docs/introduction-to-prompt-design)
- [AssemblyAI](https://www.assemblyai.com/docs/guides/lemur-best-practices)

**Videos**
- [Jeremy Howard](https://www.youtube.com/watch?v=jkrNMKz9pWU&t=1475s)
- [Andrej Karpathy](https://www.youtube.com/watch?v=bZQun8Y4L2A&t=408s)

**Meta**
- [Awesome-Prompt-Engineering](https://github.com/promptslab/Awesome-Prompt-Engineering)

## 30/10/23
### Knowledge retrieval FMs

**Main**
- [Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks](https://arxiv.org/abs/2005.11401)

**Extra**
- [Retrieval Augmented Generation: Streamlining the creation of intelligent natural language processing models](https://ai.meta.com/blog/retrieval-augmented-generation-streamlining-the-creation-of-intelligent-natural-language-processing-models/)
- [Dense Passage Retrieval for Open-Domain Question Answering](https://arxiv.org/pdf/2004.04906.pdf)
- [Lost in the Middle: How Language Models Use Long Contexts](https://arxiv.org/pdf/2307.03172.pdf)
- [Self-RAG: Learning to Retrieve, Generate And Critique Through Self-Reflection](https://arxiv.org/pdf/2310.11511.pdf)

## 06/11/23
### Current challenges and future directions in safety evaluations for generative AI

**Main**
- [Sociotechnical Safety Evaluation of Generative AI Systems](https://arxiv.org/pdf/2310.11986.pdf)

**Extras**
- [Challenges in evaluating AI systems - Anthropic](https://www.anthropic.com/index/evaluating-ai-systems)
- [AI and Catastrophic Risk - Y. Bengio](https://www.journalofdemocracy.org/ai-and-catastrophic-risk/)

## 13/11/23
### Technical: Introduction to Diffusion models

There are plenty of blog-posts and top level overviews of diffusion models which explain the main idea of, 'running a noisy blurring process backwards from the noise', however for more technical reading (which I will warn are quite heavy on the maths) the main two papers are:
- [Denoising Diffusion Probabilistic Models](https://arxiv.org/pdf/2006.11239.pdf)
- [DENOISING DIFFUSION IMPLICIT MODELS](https://arxiv.org/pdf/2010.02502.pdf)

Both are about the sampling methods used in the process (notably without the inclusion of context that allows for text-to-image generation). For a general overview the following is fairly good:
- [Diffusion Models: A Comprehensive Survey of Methods and Applications](https://arxiv.org/pdf/2209.00796.pdf)

And if you're curious (and want spoilers) about stable diffusion and latent diffusion models [this is the main paper](https://arxiv.org/pdf/2112.10752.pdf).

## 20/11/23
### Transformers for coding/software engineering

**Main**
- [The EarlyBIRD Catches the Bug: On Exploiting Early Layers of Encoder Models for More Efficient Code Classification](https://arxiv.org/abs/2305.04940)

**Extra**
- [Large Language Models for Software Engineering: Survey and Open Problems](https://arxiv.org/abs/2310.03533)
- [A Systematic Evaluation of Large Language Models of Code](https://arxiv.org/abs/2202.13169)
- [Automated Program Repair in the Era of Large Pre-trained Language Models](https://lingming.cs.illinois.edu/publications/icse2023a.pdf)
- [A Survey on Language Models for Code](https://arxiv.org/pdf/2311.07989v1.pdf)

## 04/12/23
### Guidance for Safe Foundation Model Deployment

**Main**
- [PAI’s Guidance for Safe Foundation Model Deployment](https://partnershiponai.org/modeldeployment/)

## 11/12/23
### Stable Diffusion

**Main**
- [High-Resolution Image Synthesis with Latent Diffusion Models](https://arxiv.org/pdf/2112.10752.pdf).

## 08/01/24
### Benchmarking AI applications on GPUs

**Main**
- [Benchmarking AI applications on GPUs Slides PDF](https://github.com/alan-turing-institute/foundation-models-reading-group/blob/main/sessions/20-benchmarking-gpus/transformers-rcp-benchmarking.pdf)

**Extra**
- [Repo containing write-up and LaTeX source for the slides](https://github.com/alan-turing-institute/rc-gpt2-performance-benchmarking-workspace) (may not be available immediately)
- [lightning-GPT](https://github.com/Lightning-Universe/lightning-GPT)
- [Brendan Bycroft's LLM Viz](https://bbycroft.net/llm)
- [Hacked visualisaion for illustrating GPT-2 models](https://github.com/llewelld/llm-viz/tree/gpt2)

## 15/01/24
### Retentive Networks

**Main**
- [Retentive Network: A Successor to Transformer for Large Language Models](https://arxiv.org/abs/2307.08621)

## 22/01/24
### Spatial Graph Patterning of Filamentous Structures

**Main**
- [GRACE - Graph Representation Analysis for Connected Embeddings](https://github.com/alan-turing-institute/grace)

## 29/01/24
### Vision Transformers Need Registers

**Main**
- [Vision Transformers Need Registers](https://arxiv.org/abs/2309.16588)

**Extra**
- [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/abs/2010.11929)

## 05/02/24
### Existential Risk of AI?

**Main**
- [Preventing an AI-related catastrophe](https://80000hours.org/problem-profiles/artificial-intelligence/)

**Extra**
- [Podcast: The 80,000 Hours Podcast on Artificial Intelligence](https://80000hours.org/podcast/on-artificial-intelligence/)
- Book: Nick Bostrom - "Superintelligence"
- Book: Toby Ord - "The Precipice"

## 12/02/24
### Mechanistic interpretability

**Main** 
- [(2020) Zoom In: An Introduction to Circuits](https://distill.pub/2020/circuits/zoom-in/)
- [(2021) A Mathematical Framework for Transformer Circuits](https://transformer-circuits.pub/2021/framework/index.html)

**Supplementary**
- [CVPR tutorial: Intro to Circuits in CNNs by Chris Olah](https://www.youtube.com/watch?v=gXsKyZ_Y_i8)
- [Transformer Circuits Playlist](https://www.youtube.com/watch?v=V3NQaDR3xI4&list=PLoyGOS2WIonajhAVqKUgEMNmeq3nEeM51)
- [Neel Nanda's Walkthrough: A Mathematical Framework for Transformer Circuits](https://www.youtube.com/watch?v=KV5gbOmHbjU)

**Extras**
- [Build GPT2 from scratch - Neel Nanda](https://www.youtube.com/watch?v=bOYE6E8JrtU&t=2s)
- [Mechinterp vs Neuroscience - Chris Olah](https://colah.github.io/notes/interp-v-neuro/)

## 19/02/24
### Longitudinal NLP

**Main**
- [Combining Hierachical VAEs with LLMs for Clinically Meaningful Timeline Summarisation in Social Media](https://arxiv.org/pdf/2401.16240.pdf)
- [Sig-Networks Toolkit: Signature Networks for Longitudinal Language Modelling](https://arxiv.org/pdf/2312.03523.pdf)

**Extra**
- [Identifying Moments of Change from Longitudinal User Text](https://aclanthology.org/2022.acl-long.318.pdf)
- [ROFORMER: Enhanced Transformer with Rotary Position Embedding](https://arxiv.org/pdf/2104.09864.pdf)
- [Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?](https://arxiv.org/pdf/2202.12837.pdf)

## 26/02/24
### Machine Translation Quality Estimation

## 04/03/24
### Expanding participatory governance for LLMs: case studies from BigCode, Aya Initiative, and Collective Intelligence Project

**Main**
- [Towards Openness Beyond Open Access: User Journeys through 3 Open AI Collaboratives](https://arxiv.org/abs/2301.08488)
- [The BigCode Project Governance Card](https://arxiv.org/abs/2312.03872)
- Aya Initiative: [website](https://txt.cohere.com/aya-multilingual/), [data paper](https://cohere.com/research/papers/aya-dataset-paper-2024-02-13)
- [Collective Intelligence Project white paper](https://cip.org/whitepaper)

## 11/03/24
### Applying Vision Transformers in Neuroscience

**Main**
- [2022 in review: neuroAI comes of age](https://xcorr.net/2023/01/01/2022-in-review-neuroai-comes-of-age/)
- [Towards a Foundation Model of the Mouse Visual Cortex](https://www.biorxiv.org/content/10.1101/2023.03.21.533548v2)
- [V1T: large-scale mouse V1 response prediction using a Vision Transformer](https://openreview.net/forum?id=qHZs2p4ZD4)

## 18/03/24
### Not even a Chinese Room: evaluating LLMs on code simulation

**Main**
- [CodeMind: A Framework to Challenge Large Language Models for Code Reasoning](https://arxiv.org/pdf/2402.09664.pdf)
- [Functional Benchmarks for Robust Evaluation of Reasoning Performance, and the Reasoning Gap](https://arxiv.org/pdf/2402.19450.pdf)
- [The Counterfeit Conundrum: Can Code Language Models Grasp the Nuances of Their Incorrect Generations?](https://arxiv.org/pdf/2402.19475.pdf)
- [THE GENERATIVE AI PARADOX: “What It Can Create, It May Not Understand”](https://openreview.net/pdf?id=CF8H8MS5P8)

## 08/04/24
### Paper overviews

**Main**
- [The Era of 1-bit LLMs: All Large Language Models are in 1.58 Bits](https://arxiv.org/pdf/2402.17764)
- [AI Transparancy Technique](https://www.ai-transparency.org/)
- [Spotting LLMs With Binoculars: Zero-Shot Detection of Machine-Generated Text](https://arxiv.org/abs/2401.12070)
- [Binoculars GitHub repo](https://github.com/ahans30/Binoculars?tab=readme-ov-file)

## 15/04/24
### Natural Logic-based Fact Verification with LLMs

## 22/04/24
### Learn how to learn and distil during learning - Using meta-learning and second order optimisation to prune the model

**Main**
- [Fisher-Legendre (FishLeg) optimization of deep neural networks](https://openreview.net/pdf?id=c9lAOPvQHS)
- [Second order derivatives for network pruning: Optimal Brain Surgeon](https://proceedings.neurips.cc/paper/1992/file/303ed4c69846ab36c2904d3ba8573050-Paper.pdf)
- [The Optimal BERT Surgeon: Scalable and Accurate Second-Order Pruning for Large Language Models](https://arxiv.org/pdf/2203.07259.pdf)

## 29/04/24
### How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions

**Main**
- [How to Catch an AI Liar: Lie Detection in Black-Box LLMs by Asking Unrelated Questions](https://arxiv.org/abs/2309.15840)

## 13/05/24
### Overview of LLM Security

**Main**
- [HarmBench: A Standardized Evaluation Framework for Automated Red Teaming and Robust Refusal](https://arxiv.org/pdf/2402.04249)
- [FINE-TUNING ALIGNED LANGUAGE MODELS COMPROMISES SAFETY, EVEN WHEN USERS DO NOT INTEND TO!](https://arxiv.org/pdf/2310.03693)

## 20/05/24
### KAN: Kolmogorov-Arnold Networks

**Main**
- [KAN: Kolmogorov-Arnold Networks](https://arxiv.org/abs/2404.19756)

## 04/06/24
### Invited Talk - 

**Abstract**
It has now been a decade since the first adversarial examples were demonstrated on deep learning models. And yet, even still, we can not robustly classify MNIST images better than LeNet-5 or ImageNet images better than AlexNet. But now, more than ever, we need robust machine learning models. And not only robust to evasion attack: but also robust to poisoning, stealing, and many other attacks. In this talk I survey the current progress we have made on adversarial machine learning. While we have made many significant advances in making attacks practical, we have had made considerably less progress on defences. Making progress towards addressing these challenges will be of the highest importance in the coming years.

## 01/07/24
### A perspective on the fundamentals of transformers

- [ICASSP Tutorial](https://sites.usc.edu/aif4s/2024/04/14/icassp-2024-tutorial-on-fundamentals-of-transformers/)
- Transformers primer
	- [Vaswani et al.'17](https://arxiv.org/abs/1706.03762)
	- [Elhage et al.'21](https://transformer-circuits.pub/2021/framework/index.html)
- Optimisation
	- [Ji et al.'20](https://proceedings.mlr.press/v125/ji20a.html)
	- [Tarzanagh et al.'23b](https://arxiv.org/abs/2308.16898)
	- [Tarzanagh et al.'23a](https://arxiv.org/abs/2306.13596)
	- [Vasudeva et al.'24](https://arxiv.org/abs/2402.05738)
- Approximation
	- [Yun et al.'19](https://arxiv.org/abs/1912.10077)
	- [Kajitsuka & Sato'23](https://arxiv.org/abs/2307.14023)
	- [Guo et al.'19](https://arxiv.org/abs/1902.09113)
	- [Child et al.'19](https://arxiv.org/abs/1904.10509)
	- [Yun et al.'20](https://arxiv.org/abs/2006.04862)
	- [Beltagy et al.'20](https://arxiv.org/abs/2004.05150)
	- [Zaheer et al.'20](https://arxiv.org/abs/2007.14062)
- Memorisation
	- [Blog](https://ml-jku.github.io/hopfield-layers/)
	- [Hopfield'82](https://www.pnas.org/doi/abs/10.1073/pnas.79.8.2554)
	- [Krotov, Hopfield'16](https://arxiv.org/abs/1606.01164)
	- [Dermircigil et al.'17](https://arxiv.org/abs/1702.01929)
	- [Krotov, Hopfield'20](https://arxiv.org/abs/2008.06996)
	- [Ramsauer et al.'20](https://arxiv.org/abs/2008.02217)
- In-context learning
	- [Oswald et al.'22](https://arxiv.org/abs/2212.07677)
	- [Xie et al.'21](https://arxiv.org/abs/2111.02080)

## 08/07/24
### Equally Safe Online? A participatory approach to tackling Gender-Based Violence

We are in the midst of an ‘epidemic of online abuse’, which disproportionately affects women and minoritised groups. In recent years, technology companies and computer science researchers have made efforts to automate the identification of hate speech and other toxic or abusive language. However, existing resources are limited in a number of important ways, such as their lack of theoretical grounding and stakeholder input.The EPSRC funded project Equally Safe Online aims to harness stakeholder expertise to co-design resources and methods to tackle online GBV.
In this talk, I will discuss outcomes and ongoing work from the project, focusing on participatory design for NLP, perspectivist approaches to dataset creation, and generation of counterspeech against hateful language.

## 05/08/24
### The growth of parallelism in machine learning inference

When I started working on machine learning inference four years ago a typical model would run on a handful of CPU cores. We needed to think about distributing work between threads, but the systems-level problems and abstractions were well understood. Fast forward to today and machine learning models are so large that even a "small" language model can have billions of parameters and run across a multi-GPU system. In this talk I am going to go on an end-to-end journey through the implementation of these models. We will see some of the different problems which emerge in parallelism and distributed computing, and some of the places where I think we are lacking good abstractions.

## 12/08/24
### Llama 3.1 Report Overview

- [The Llama 3 Herd of Models](https://ai.meta.com/research/publications/the-llama-3-herd-of-models/)
- [GQA: Training Generalized Multi-Query Transformer Models from Multi-Head Checkpoints](https://arxiv.org/pdf/2305.13245)
- [RoFormer: Enhanced Transformer with Rotary Position Embedding](https://arxiv.org/pdf/2104.09864)

## 19/08/24
### Overview of Knowledge Graphs

- [A Survey on Knowledge Graphs: Representation, Acquisition, and Applications](https://arxiv.org/pdf/2002.00388)

## 28/08/24
### Mixture of Experts

- [Mixture of Experts Explained  - Huggingface blog](https://huggingface.co/blog/moe)
- [Applying Mixture of Experts in LLM Architectures - Nvidia blog](https://developer.nvidia.com/blog/applying-mixture-of-experts-in-llm-architectures/)

## 03/09/24
### Sociotechnical Safety Evaluation of AI systems

Generative AI systems create risks which must be evaluated in order to be managed or mitigated. Current approaches to AI safety evaluation are primarily focused on assessing technical artefacts in isolation, and so may miss hazards that arise through human-AI-interaction or wide-scale deployment. In this talk, I introduce a sociotechnical approach to AI safety evaluation that aims to capture relevant complexity, to provide a more comprehensive safety assessment. In addition, different evaluation *goals* require matching evaluation *methods*. Reviewing the current landscape of AI safety evaluation, I point out strengths and key gaps that need to be addressed. I close by discussing trade-offs and open challenges at the frontier of AI safety evaluation research.

- [Sociotechnical Safety Evaluation of Generative AI Systems](https://deepmind.google/research/publications/45425/)

## Miscellaneous

### Tokenizers and Huggingface tutorial

**Main**
- [Huggingface Tokenizer tutorial](https://huggingface.co/learn/nlp-course/chapter2/4?fw=pt)
- [Huggingface `transformers` course](https://huggingface.co/learn/nlp-course/chapter2/1?fw=pt)
